{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "from skimage import io\n",
    "from shutil import copyfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from .csv file\n",
    "* train-images-boxable.csv file contains the image name and image url\n",
    "* train-annotations-bbox.csv file contains the bounding box info with the image id (name) and the image label name\n",
    "* class-descriptions-boxable.csv file contains the image label name corresponding to its class name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_boxable_fname = 'train-images-boxable.csv'\n",
    "annotations_bbox_fname = 'train-annotations-bbox.csv'\n",
    "class_descriptions_fname = 'class-descriptions-boxable2.csv'\n",
    "\n",
    "annotations_cols = ['ImageID','LabelName','XMin','XMax','YMin','YMax']\n",
    "annotations_types = {\n",
    "\t'ImageID': np.dtype(str),\n",
    "\t'LabelName': np.dtype(str),\n",
    "\t'Xmin': np.dtype(float),\n",
    "\t'Xmax': np.dtype(float),\n",
    "\t'Ymin': np.dtype(float),\n",
    "\t'Ymax': np.dtype(float) }\n",
    "\n",
    "images_boxable = pd.read_csv(images_boxable_fname)\n",
    "annotations_bbox = pd.read_csv(annotations_bbox_fname, usecols=annotations_cols,dtype=annotations_types)\n",
    "class_descriptions = pd.read_csv(class_descriptions_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define preprocessing parameters\n",
    "* **class_desc:** list of all unique class descriptions, as written on the .csv files\n",
    "* **classes:** manually written short terms for each class\n",
    "* **imgs_per_class:** (imgs_per_class) X (N_CLASSES) = total amount of images of dataset to download\n",
    "* **n_train_imgs:** amount of images reserved for training, leftover images used for testing\n",
    "\n",
    "The default parameters are the ones used for the BodyParts (BP) Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_desc = ['Human arm','Human beard','Human ear','Human eye','Human face',\n",
    "'Human foot','Human hair','Human hand','Human head','Human leg','Human mouth','Human nose','Skull']\n",
    "classes = ['arm','beard','ear','eye','face','foot','hair','hand','head','leg','mouth','nose','skull']\n",
    "N_CLASSES = len(classes)\n",
    "imgs_per_class = 100\n",
    "n_train_imgs = 80\n",
    "\n",
    "base_path = 'BP'\n",
    "csv_path = 'BP/classCSVs'\n",
    "data_path = 'BP/data'\n",
    "\n",
    "os.mkdir(base_path)\n",
    "os.mkdir(csv_path)\n",
    "os.mkdir(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write subsets of OpenImagesDB to a .csv\n",
    "\n",
    "For each class in the custom dataset, I obtain a set with all annotations respective to that class. This set is then randomly shuffled, and only a subset of it is selected for use. A .csv is written with the urls of all images of the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human arm\n",
      "Human beard\n",
      "Human ear\n",
      "Human eye\n",
      "Human face\n",
      "Human foot\n",
      "Human hair\n",
      "Human hand\n",
      "Human head\n",
      "Human leg\n",
      "Human mouth\n",
      "Human nose\n",
      "Skull\n"
     ]
    }
   ],
   "source": [
    "label_names = []\n",
    "for i in range(N_CLASSES):\n",
    "    class_pd = class_descriptions[class_descriptions['class']==class_desc[i]]\n",
    "    label_name_class = class_pd['name'].values[0]\n",
    "    label_names.append(label_name_class)\n",
    "    class_bbox = annotations_bbox[annotations_bbox['LabelName']==label_name_class]\n",
    "    class_img_id = np.unique(class_bbox['ImageID'])\n",
    "    copy_class_id = class_img_id.copy()\n",
    "    random.seed(1)\n",
    "    random.shuffle(copy_class_id)\n",
    "\n",
    "    subclass_img_id = copy_class_id[:imgs_per_class]\n",
    "    subclass_img_url = [images_boxable[images_boxable['image_name']==name+'.jpg'] for name in subclass_img_id]\n",
    "    subclass_pd = pd.DataFrame()\n",
    "    for j in range(len(subclass_img_url)):\n",
    "        subclass_pd = subclass_pd.append(subclass_img_url[j], ignore_index= True)\n",
    "    subclass_pd.to_csv(os.path.join(csv_path, classes[i]+'_img_url.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_CLASSES):\n",
    "    subclass_pd = pd.read_csv(os.path.join(base_path, csv_path, classes[i]+'_img_url.csv'))\n",
    "    subclass_img_url = subclass_pd['image_url'].values\n",
    "    saved_dir = os.path.join(data_path,classes[i])\n",
    "    os.mkdir(saved_dir)\n",
    "    for url in subclass_img_url:\n",
    "        img = io.imread(url)\n",
    "        saved_path = os.path.join(saved_dir, url[-20:])\n",
    "        io.imsave(saved_path, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset format for network\n",
    "\n",
    "Train and test directories are created, and the set of downloaded images is divided as defined by n_train_imgs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join(base_path, 'train')\n",
    "os.mkdir(train_path)\n",
    "test_path = os.path.join(base_path, 'test')\n",
    "os.mkdir(test_path)\n",
    "for i in range(N_CLASSES):\n",
    "    \n",
    "    all_imgs = os.listdir(os.path.join(data_path, classes[i]))\n",
    "    all_imgs = [f for f in all_imgs if not f.startswith('.')]\n",
    "    random.seed(1)\n",
    "    random.shuffle(all_imgs)\n",
    "    \n",
    "    train_imgs = all_imgs[:n_train_imgs]\n",
    "    test_imgs = all_imgs[n_train_imgs:]\n",
    "    \n",
    "    # Copy each classes' images to train directory\n",
    "    for j in range(len(train_imgs)):\n",
    "        original_path = os.path.join(os.path.join(base_path, 'data', classes[i]), train_imgs[j])\n",
    "        new_path = os.path.join(train_path, train_imgs[j])\n",
    "        copyfile(original_path, new_path)\n",
    "    \n",
    "    # Copy each classes' images to test directory\n",
    "    for j in range(len(test_imgs)):\n",
    "        original_path = os.path.join(os.path.join(base_path, 'data', classes[i]), test_imgs[j])\n",
    "        new_path = os.path.join(test_path, test_imgs[j])\n",
    "        copyfile(original_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "format of dataframes: (fname_path, xmin, xmax, ymin, ymax, class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse train_imgs 1033; Number of boxes: 14059\r"
     ]
    }
   ],
   "source": [
    "train_df = pd.DataFrame(columns=['FileName', 'XMin', 'XMax', 'YMin', 'YMax', 'ClassName'])\n",
    "# Find boxes in each image and put them in a dataframe\n",
    "train_imgs = os.listdir(train_path)\n",
    "train_imgs = [name for name in train_imgs if not name.startswith('.')]\n",
    "\n",
    "for i in range(len(train_imgs)):\n",
    "\tsys.stdout.write('Parse train_imgs ' + str(i) + '; Number of boxes: ' + str(len(train_df)) + '\\r')\n",
    "\tsys.stdout.flush()\n",
    "\timg_name = train_imgs[i]\n",
    "\timg_id = img_name[0:16]\n",
    "\ttmp_df = annotations_bbox[annotations_bbox['ImageID']==img_id]\n",
    "\tfor index, row in tmp_df.iterrows():\n",
    "\t\tlabelName = row['LabelName']\n",
    "\t\tfor i in range(len(label_names)):\n",
    "\t\t\tif labelName == label_names[i]:\n",
    "\t\t\t\ttrain_df = train_df.append({'FileName': img_name, \n",
    "\t\t\t\t\t\t\t\t\t\t\t'XMin': row['XMin'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t'XMax': row['XMax'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t'YMin': row['YMin'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t'YMax': row['YMax'], \n",
    "\t\t\t\t\t\t\t\t\t\t\t'ClassName': classes[i]}, \n",
    "\t\t\t\t\t\t\t\t\t\t\tignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse test_imgs 258; Number of boxes: 3441\r"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame(columns=['FileName', 'XMin', 'XMax', 'YMin', 'YMax', 'ClassName'])\n",
    "\n",
    "# Find boxes in each image and put them in a dataframe\n",
    "test_imgs = os.listdir(test_path)\n",
    "test_imgs = [name for name in test_imgs if not name.startswith('.')]\n",
    "\n",
    "for i in range(len(test_imgs)):\n",
    "    sys.stdout.write('Parse test_imgs ' + str(i) + '; Number of boxes: ' + str(len(test_df)) + '\\r')\n",
    "    sys.stdout.flush()\n",
    "    img_name = test_imgs[i]\n",
    "    img_id = img_name[0:16]\n",
    "    tmp_df = annotations_bbox[annotations_bbox['ImageID']==img_id]\n",
    "    for index, row in tmp_df.iterrows():\n",
    "        labelName = row['LabelName']\n",
    "        for i in range(len(label_names)):\n",
    "            if labelName == label_names[i]:\n",
    "                test_df = test_df.append({'FileName': img_name, \n",
    "                                            'XMin': row['XMin'], \n",
    "                                            'XMax': row['XMax'], \n",
    "                                            'YMin': row['YMin'], \n",
    "                                            'YMax': row['YMax'], \n",
    "                                            'ClassName': classes[i]}, \n",
    "                                           ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save each dataframe to .csv under the dataset's directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv(os.path.join(base_path, 'train.csv'))\n",
    "test_df.to_csv(os.path.join(base_path, 'test.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write train.csv to annotation.txt\n",
    "\n",
    "Format of annotation.txt: (imgname, x1, y1, x2, y2, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(os.path.join(base_path, 'train.csv'))\n",
    "\n",
    "f= open(base_path + \"/annotations.txt\",\"w+\")\n",
    "for idx, row in train_df.iterrows():\n",
    "\timg = cv2.imread((base_path + '/train/' + row['FileName']))\n",
    "\theight, width = img.shape[:2]\n",
    "\tx1 = int(row['XMin'] * width)\n",
    "\tx2 = int(row['XMax'] * width)\n",
    "\ty1 = int(row['YMin'] * height)\n",
    "\ty2 = int(row['YMax'] * height)\n",
    "\tfileName = row['FileName']\n",
    "\tclassName = row['ClassName']\n",
    "\tf.write(fileName + ',' + str(x1) + ',' + str(y1) + ',' + str(x2) + ',' + str(y2) + ',' + className + '\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
